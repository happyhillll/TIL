# TIL(일) 🤛🏻
- 베네치아 일정 짜기 : 맛집 정리
- 5-1차 CO2 태그 완료
#### 4장 word2vec 복습
- CBOW의 문제점
    - 입력층의 one-hot 표현과 weight(in)행렬의 곱 계산이 너무 크다.
    - hidden layer와 weight(out) 행렬의 곱 & softmax 계산량이 너무 많다.
- 해결
    - Embedding 계층 추가하여 필요없는 원소까지 곱할 필요 없게끔
    - 다중분류에서 이중 분류로 (계산과정이 간단해짐)
    - negative sampling (적은 수의 부정적 예를 sampling 하여 사용함으로써 분류가 더 정확해짐)
#### 5장 RNN 5.3절 까지 완료
- word2vec의 문제점
    - feed forward 신경망 : 흐름이 단방향이기 때문에 시계열 데이터에 취약하다.
    - CBOW에서는 맥락의 길이가 고정되어있기 때문에 11번째 전의 맥락을 불러올 수 없다.
    - CBOW는 맥락 안의 단어 순서를 고려하지 않는다.
- RNN
    - 맥락이 아무리 길어도 맥락의 정보를 기억할 수 있다.
    - Truncated BPTT : 큰 시계열 데이터를 적당한 크기로 끊어서 작은 신경망 여러개를 만들어 오차역전파법 수행한다.
    - RNN 계층의 계산 그래프 그리기

# 내일도 화이팅 ✌🏻
- 베네치아 부라노까지 가는 섬 배 알아보기
- 요가ㅎㅎ🧘🏻‍♀️
- 이교수님 연락
- RNN 마무리
- 태블로
- 포트폴리오 수정